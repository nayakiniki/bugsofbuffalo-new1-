{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêÉ Bugs of Buffalo - Model Training Notebook\n",
    "\n",
    "This notebook trains the cattle breed classification model using transfer learning with EfficientNetB0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "FINE_TUNE_EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "DATA_DIR = '../data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "print(f\"Found {NUM_CLASSES} classes: {class_names}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    pooling=None\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint(\n",
    "        '../saved_model/best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training\n",
    "print(\"Starting initial training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "print(\"Starting fine-tuning...\")\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "fine_tune_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=fine_tune_callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and artifacts\n",
    "save_dir = '../saved_model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(save_dir, 'bugs_of_buffalo_model.h5')\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Save class mapping\n",
    "class_mapping = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "mapping_path = os.path.join(save_dir, 'class_mapping.json')\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(class_mapping, f, indent=2)\n",
    "print(f\"Class mapping saved to {mapping_path}\")\n",
    "\n",
    "# Save training history\n",
    "history_path = os.path.join(save_dir, f'training_history_{timestamp}.json')\n",
    "history_dict = {\n",
    "    'training_history': history.history,\n",
    "    'fine_tune_history': fine_tune_history.history,\n",
    "    'class_names': class_names,\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "print(f\"Training history saved to {history_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.plot(range(len(history.history['accuracy']), \n",
    "             len(history.history['accuracy']) + len(fine_tune_history.history['accuracy'])),\n",
    "         fine_tune_history.history['accuracy'], label='Fine-tuning Accuracy')\n",
    "ax1.plot(range(len(history.history['val_accuracy']), \n",
    "             len(history.history['val_accuracy']) + len(fine_tune_history.history['val_accuracy'])),\n",
    "         fine_tune_history.history['val_accuracy'], label='Fine-tuning Val Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.plot(range(len(history.history['loss']), \n",
    "             len(history.history['loss']) + len(fine_tune_history.history['loss'])),\n",
    "         fine_tune_history.history['loss'], label='Fine-tuning Loss')\n",
    "ax2.plot(range(len(history.history['val_loss']), \n",
    "             len(history.history['val_loss']) + len(fine_tune_history.history['val_loss'])),\n",
    "         fine_tune_history.history['val_loss'], label='Fine-tuning Val Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "# Precision\n",
    "ax3.plot(history.history['precision'], label='Training Precision')\n",
    "ax3.plot(history.history['val_precision'], label='Validation Precision')\n",
    "ax3.set_title('Model Precision')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Precision')\n",
    "ax3.legend()\n",
    "\n",
    "# Recall\n",
    "ax4.plot(history.history['recall'], label='Training Recall')\n",
    "ax4.plot(history.history['val_recall'], label='Validation Recall')\n",
    "ax4.set_title('Model Recall')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Recall')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../saved_model/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "final_loss, final_accuracy, final_precision, final_recall = model.evaluate(validation_generator, verbose=0)\n",
    "print(\"Final Evaluation Results:\")\n",
    "print(f\"Validation Loss: {final_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {final_precision:.4f}\")\n",
    "print(f\"Validation Recall: {final_recall:.4f}\")\n",
    "\n",
